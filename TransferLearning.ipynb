{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, Concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unet_with_resnet50(input_shape=(256, 256, 3)):\n",
    "    # Load ResNet50 pretrained weights, excluding the top layers\n",
    "    resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Encoder: Extract features from ResNet50\n",
    "    encoder_outputs = [\n",
    "        resnet50.get_layer(\"conv1_relu\").output,  # Stage 1\n",
    "        resnet50.get_layer(\"conv2_block3_out\").output,  # Stage 2\n",
    "        resnet50.get_layer(\"conv3_block4_out\").output,  # Stage 3\n",
    "        resnet50.get_layer(\"conv4_block6_out\").output,  # Stage 4\n",
    "        resnet50.get_layer(\"conv5_block3_out\").output,  # Stage 5\n",
    "    ]\n",
    "\n",
    "    # Decoder: Create U-Net decoder using transpose convolutions or upsampling\n",
    "    def decoder_block(input_tensor, skip_tensor, num_filters):\n",
    "        x = Conv2DTranspose(num_filters, (3, 3), strides=2, padding=\"same\")(input_tensor)\n",
    "        x = Concatenate()([x, skip_tensor])\n",
    "        x = Conv2D(num_filters, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "        x = Conv2D(num_filters, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "        return x\n",
    "\n",
    "    # Decoder steps\n",
    "    x = encoder_outputs[-1]  # Start from the bottleneck\n",
    "    x = decoder_block(x, encoder_outputs[-2], 512)\n",
    "    x = decoder_block(x, encoder_outputs[-3], 256)\n",
    "    x = decoder_block(x, encoder_outputs[-4], 128)\n",
    "    x = decoder_block(x, encoder_outputs[-5], 64)\n",
    "\n",
    "    # Final layer\n",
    "    outputs = Conv2D(1, (1, 1), activation=\"sigmoid\")(x)\n",
    "\n",
    "    # Create the U-Net model\n",
    "    model = Model(inputs=resnet50.input, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "model = unet_with_resnet50(input_shape=(256, 256, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Program Files\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNetResNet50(\n",
      "  (encoder1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (encoder2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder5): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder4): Sequential(\n",
      "    (0): ConvTranspose2d(2048, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (decoder3): Sequential(\n",
      "    (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (decoder2): Sequential(\n",
      "    (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (decoder1): Sequential(\n",
      "    (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (final): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "class UNetResNet50(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(UNetResNet50, self).__init__()\n",
    "        resnet = resnet50(pretrained=pretrained)\n",
    "\n",
    "        # Extract ResNet encoder layers\n",
    "        self.encoder1 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool)\n",
    "        self.encoder2 = resnet.layer1\n",
    "        self.encoder3 = resnet.layer2\n",
    "        self.encoder4 = resnet.layer3\n",
    "        self.encoder5 = resnet.layer4\n",
    "\n",
    "        # Decoder layers\n",
    "        self.decoder4 = self._decoder_block(2048, 1024)\n",
    "        self.decoder3 = self._decoder_block(1024, 512)\n",
    "        self.decoder2 = self._decoder_block(512, 256)\n",
    "        self.decoder1 = self._decoder_block(256, 64)\n",
    "\n",
    "        # Final output layer\n",
    "        self.final = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def _decoder_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(enc1)\n",
    "        enc3 = self.encoder3(enc2)\n",
    "        enc4 = self.encoder4(enc3)\n",
    "        enc5 = self.encoder5(enc4)\n",
    "\n",
    "        # Decoder\n",
    "        dec4 = self.decoder4(enc5) + enc4\n",
    "        dec3 = self.decoder3(dec4) + enc3\n",
    "        dec2 = self.decoder2(dec3) + enc2\n",
    "        dec1 = self.decoder1(dec2) + enc1\n",
    "\n",
    "        # Final output\n",
    "        out = self.final(dec1)\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "# Example usage\n",
    "model = UNetResNet50(pretrained=True)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 142\n",
      "Validation samples: 36\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_734']. Received: the structure of inputs=*\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 12s/step - accuracy: 0.6734 - loss: 31786.8398 - mean_io_u: 0.5770 - val_accuracy: 0.9510 - val_loss: 2338.7378 - val_mean_io_u: 0.5000\n",
      "Epoch 2/2\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 13s/step - accuracy: 0.9582 - loss: 425.5397 - mean_io_u: 0.5000 - val_accuracy: 0.9511 - val_loss: 0.5811 - val_mean_io_u: 1.0000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.9504 - loss: 0.5811 - mean_io_u: 1.0000\n",
      "Validation Loss: 0.5811240673065186\n",
      "Validation Accuracy: 0.9510905146598816\n",
      "Validation Mean IoU: 0.9999998807907104\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import random\n",
    "\n",
    "# Set image dimensions and batch size\n",
    "IMG_HEIGHT, IMG_WIDTH = 256, 256\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# Paths\n",
    "DATASET_DIR = \"D:/FinalYearProject/Datasets/Wenchuan\"  # Replace with the path to your dataset folder\n",
    "IMG_DIR = os.path.join(DATASET_DIR, \"img\")\n",
    "MASK_DIR = os.path.join(DATASET_DIR, \"mask\")\n",
    "\n",
    "\n",
    "# Helper function to load images and masks\n",
    "def load_data(img_dir, mask_dir):\n",
    "    img_paths = sorted(\n",
    "        [os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith(\".tif\")]\n",
    "    )\n",
    "    mask_paths = sorted(\n",
    "        [os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith(\".TIF\")]\n",
    "    )\n",
    "\n",
    "    images = [\n",
    "        img_to_array(load_img(img, target_size=(IMG_HEIGHT, IMG_WIDTH))) / 255.0\n",
    "        for img in img_paths\n",
    "    ]\n",
    "    masks = [\n",
    "        img_to_array(\n",
    "            load_img(mask, target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode=\"grayscale\")\n",
    "        )\n",
    "        / 255.0\n",
    "        for mask in mask_paths\n",
    "    ]\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "\n",
    "# Load images and masks\n",
    "images, masks = load_data(IMG_DIR, MASK_DIR)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    images, masks, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "\n",
    "\n",
    "# Define a U-Net model\n",
    "def build_unet(input_shape):\n",
    "    inputs = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(c1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(p1)\n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(c2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(p2)\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(c3)\n",
    "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(p3)\n",
    "    c4 = tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(c4)\n",
    "    p4 = tf.keras.layers.MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5 = tf.keras.layers.Conv2D(1024, (3, 3), activation=\"relu\", padding=\"same\")(p4)\n",
    "    c5 = tf.keras.layers.Conv2D(1024, (3, 3), activation=\"relu\", padding=\"same\")(c5)\n",
    "\n",
    "    # Decoder\n",
    "    u6 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding=\"same\")(\n",
    "        c5\n",
    "    )\n",
    "    u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "    c6 = tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(u6)\n",
    "    c6 = tf.keras.layers.Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(c6)\n",
    "\n",
    "    u7 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding=\"same\")(\n",
    "        c6\n",
    "    )\n",
    "    u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "    c7 = tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(u7)\n",
    "    c7 = tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(c7)\n",
    "\n",
    "    u8 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding=\"same\")(\n",
    "        c7\n",
    "    )\n",
    "    u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "    c8 = tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(u8)\n",
    "    c8 = tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(c8)\n",
    "\n",
    "    u9 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding=\"same\")(c8)\n",
    "    u9 = tf.keras.layers.concatenate([u9, c1])\n",
    "    c9 = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(u9)\n",
    "    c9 = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(c9)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation=\"sigmoid\")(c9)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build the U-Net model\n",
    "model = build_unet((IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", MeanIoU(num_classes=2)],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train, validation_data=(X_val, y_val), batch_size=BATCH_SIZE, epochs=2\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_accuracy, val_iou = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation Mean IoU: {val_iou}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 3)\n",
      "Model expects input shape: (None, 256, 256, 3)\n",
      "Single image shape after preprocessing: (1, 256, 256, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step\n",
      "Predicted mask shape: (1, 256, 256, 1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'visualize_single_prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m binary_mask \u001b[38;5;241m=\u001b[39m (predicted_mask[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Visualize the prediction\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[43mvisualize_single_prediction\u001b[49m(SINGLE_TEST_IMAGE_PATH, predicted_mask, binary_mask)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Visualize the results\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_single_prediction\u001b[39m(image_path, predicted_mask, binary_mask):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# Load the original image for visualization\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'visualize_single_prediction' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Path to the single test image\n",
    "SINGLE_TEST_IMAGE_PATH = \"D:/FinalYearProject/Datasets/Wenchuan/img/wenchuan027.tif\"  # Replace with your image file path\n",
    "\n",
    "# Function to load and preprocess a single image\n",
    "def preprocess_image(image_path, target_size):\n",
    "    # Load the image and resize it\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    # Convert the image to an array and normalize it\n",
    "    image_array = img_to_array(image) / 255.0\n",
    "    # Add a batch dimension (required by the model)\n",
    "    image_array = np.expand_dims(image_array, axis=0)\n",
    "    return image_array\n",
    "\n",
    "# Load and preprocess the single test image\n",
    "single_image = preprocess_image(SINGLE_TEST_IMAGE_PATH, (IMG_HEIGHT, IMG_WIDTH))\n",
    "print(single_image.shape)  # Should output (1, IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "\n",
    "# Debugging: Check model input shape\n",
    "print(\"Model expects input shape:\", model.input_shape)\n",
    "\n",
    "# Load and preprocess the image\n",
    "single_image = preprocess_image(SINGLE_TEST_IMAGE_PATH, (IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "# Debugging: Check single image shape\n",
    "print(\"Single image shape after preprocessing:\", single_image.shape)\n",
    "\n",
    "# Predict the mask\n",
    "predicted_mask = model.predict(single_image)\n",
    "\n",
    "# Debugging: Check predicted mask shape\n",
    "print(\"Predicted mask shape:\", predicted_mask.shape)\n",
    "\n",
    "# Threshold the predicted mask\n",
    "binary_mask = (predicted_mask[0] > 0.5).astype(np.uint8)\n",
    "\n",
    "# # Visualize the prediction\n",
    "# visualize_single_prediction(SINGLE_TEST_IMAGE_PATH, predicted_mask, binary_mask)\n",
    "\n",
    "\n",
    "# Visualize the results\n",
    "def visualize_single_prediction(image_path, predicted_mask, binary_mask):\n",
    "    # Load the original image for visualization\n",
    "    original_image = load_img(image_path)\n",
    "    \n",
    "    # Plot the original image, predicted mask, and binary mask\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Original image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(original_image)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Predicted mask\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(predicted_mask.squeeze(), cmap=\"gray\")\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Binary mask\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(binary_mask.squeeze(), cmap=\"gray\")\n",
    "    plt.title(\"Binary Mask (Thresholded)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the prediction for the single image\n",
    "visualize_single_prediction(SINGLE_TEST_IMAGE_PATH, predicted_mask, binary_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
